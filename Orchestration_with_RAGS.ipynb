{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55dcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe68de98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"api_key\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Api key not found\")\n",
    "else:\n",
    "    print(\"Api key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a970d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Python is a high-level programming language known for readability and simplicity\",\n",
    "    \"Machine learning is a subset of AI that enables systems to learn from data.\",\n",
    "    \"RAG combines retrievable and generation to provide accurate, grounded responses.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5e0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c983eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.95707723e-02,  9.51999873e-02,  1.60213951e-02,  6.80146040e-03,\n",
       "       -8.84049833e-02,  1.42048458e-02,  5.40277660e-02,  4.56368998e-02,\n",
       "       -3.19217443e-02, -2.95636989e-02,  5.67037286e-03,  6.36049360e-03,\n",
       "        2.30016485e-02, -5.11627048e-02, -4.39477079e-02,  5.89560680e-02,\n",
       "        5.50739467e-02,  9.31472555e-02, -1.99183207e-02,  5.56547148e-03,\n",
       "       -6.06279224e-02,  7.54946619e-02, -1.02010812e-03, -3.40628847e-02,\n",
       "        4.00799699e-02,  4.76241447e-02, -3.31660882e-02, -7.22332683e-04,\n",
       "        5.98662868e-02, -8.33192468e-03, -9.59183741e-03,  5.34927063e-02,\n",
       "       -2.39231139e-02, -2.01412123e-02, -4.85539325e-02,  1.87074877e-02,\n",
       "       -2.20365617e-02,  6.23629428e-02,  4.00254037e-03,  2.97090653e-02,\n",
       "        1.27504747e-02,  1.79135846e-03, -2.17953287e-02, -8.11001360e-02,\n",
       "       -2.61422654e-04,  3.26574892e-02, -1.05920136e-02,  3.05196643e-02,\n",
       "        3.11776567e-02, -1.16894813e-02,  5.91254793e-03,  5.38987434e-03,\n",
       "        2.91767586e-02,  5.12314104e-02, -3.31499018e-02, -9.99479517e-02,\n",
       "        7.15584978e-02, -6.35875314e-02, -3.19283493e-02,  2.67297886e-02,\n",
       "       -4.80684750e-02, -2.02164650e-02,  3.95956822e-03,  4.79318537e-02,\n",
       "        1.14055872e-01, -7.27937594e-02,  2.78397053e-02,  6.54355660e-02,\n",
       "       -1.67537481e-02,  1.15544340e-02, -9.06090438e-02, -2.00257450e-02,\n",
       "       -2.25803666e-02,  1.09434806e-01,  4.32739928e-02, -4.93502105e-03,\n",
       "       -1.12912059e-03, -3.66381481e-02, -4.08190349e-03, -4.76219766e-02,\n",
       "       -9.24646482e-02,  1.63054820e-02,  3.96325393e-03,  3.18804868e-02,\n",
       "       -6.77724509e-03,  6.70539811e-02, -1.54483207e-02,  1.31447129e-02,\n",
       "       -2.06109975e-03, -6.43415153e-02, -1.77510642e-02,  2.24052798e-02,\n",
       "        2.83358842e-02, -4.31472138e-02,  3.03899348e-02,  3.56945507e-02,\n",
       "        3.26535217e-02,  8.93205926e-02, -2.13401616e-02,  7.20681995e-02,\n",
       "       -4.41078171e-02,  6.09858986e-03,  3.15974057e-02,  9.61598242e-04,\n",
       "       -5.09097576e-02, -8.34936574e-02,  2.21505295e-03, -5.59421256e-02,\n",
       "       -3.04697771e-02, -1.79337636e-02,  1.28423963e-02, -1.95411127e-02,\n",
       "       -2.47343984e-02, -4.94453795e-02, -1.10741094e-01,  6.61964994e-03,\n",
       "        8.04277956e-02, -4.32126112e-02, -2.58145370e-02,  7.37987980e-02,\n",
       "        3.65234017e-02,  4.72384207e-02, -7.34408870e-02,  3.34664322e-02,\n",
       "       -1.71663873e-02, -1.61352865e-02,  6.14989772e-02, -1.00972996e-32,\n",
       "       -6.58636505e-04, -4.42288667e-02, -5.89078059e-03, -4.33472963e-03,\n",
       "       -3.84675823e-02, -2.52559502e-02, -3.19977328e-02, -8.55811611e-02,\n",
       "        6.78976849e-02,  3.56264934e-02,  4.90457453e-02, -9.02157370e-03,\n",
       "       -3.55495932e-03,  1.25986366e-02,  1.23416875e-02,  7.38265961e-02,\n",
       "       -3.83414738e-02, -4.76925969e-02,  8.14195648e-02,  9.12535936e-03,\n",
       "       -6.72839656e-02,  1.43213049e-01,  9.45160165e-03, -4.14702436e-03,\n",
       "       -1.33043304e-01,  6.46285564e-02,  3.49483788e-02, -2.62205824e-02,\n",
       "       -4.31026332e-02,  8.03292729e-03,  1.15955090e-02,  1.24494135e-02,\n",
       "       -2.40833573e-02, -9.59442754e-04, -1.09054297e-02, -1.73879191e-02,\n",
       "       -1.18933819e-01, -3.00804130e-03, -6.41341060e-02,  3.60839814e-02,\n",
       "       -3.87536958e-02, -3.74178402e-02, -6.30439147e-02, -5.23225889e-02,\n",
       "        6.49776831e-02, -5.93678206e-02,  2.50222739e-02,  4.15211879e-02,\n",
       "       -1.79149043e-02,  1.32706597e-01,  8.00482407e-02,  3.07606366e-02,\n",
       "        2.23206040e-02,  3.48096304e-02, -4.64085229e-02,  5.17751910e-02,\n",
       "        7.43334442e-02, -7.65679330e-02, -4.08498272e-02,  1.08197436e-01,\n",
       "       -2.28408948e-02,  7.45330676e-02,  1.21635823e-02,  6.17581196e-02,\n",
       "        8.84734653e-03, -5.17181456e-02,  8.95959698e-03,  2.85185296e-02,\n",
       "        4.67934310e-02, -1.90219991e-02,  1.33601846e-02, -2.67012361e-02,\n",
       "        2.88795307e-03,  1.06873408e-01, -2.17432957e-02, -1.53007125e-02,\n",
       "        5.71343973e-02,  2.01552268e-02,  1.85527895e-02, -5.85736260e-02,\n",
       "        2.66859941e-02, -2.53530834e-02, -4.21371199e-02, -3.45805809e-02,\n",
       "       -9.78772789e-02,  2.96594631e-02, -3.48227695e-02, -6.84009716e-02,\n",
       "       -6.17050268e-02, -6.55084178e-02, -3.25227752e-02, -1.77551862e-02,\n",
       "       -1.50988046e-02,  2.59637907e-02, -3.78732793e-02,  4.74787017e-33,\n",
       "        1.19201824e-01, -5.31222075e-02,  1.20397452e-02,  7.04686567e-02,\n",
       "        3.14128995e-02,  1.36746969e-02,  8.71989876e-04,  7.00792819e-02,\n",
       "       -5.68538085e-02,  1.39187559e-01,  3.24113481e-02, -3.43046412e-02,\n",
       "       -2.14137323e-02,  1.99318398e-02,  1.08643964e-01,  8.05128142e-02,\n",
       "        2.65410580e-02,  6.80766180e-02, -2.00419873e-02,  4.87179980e-02,\n",
       "        2.36039665e-02,  4.57040481e-02,  7.23040551e-02,  2.45724134e-02,\n",
       "       -6.24113865e-02, -6.29048273e-02,  8.92215893e-02, -8.21970552e-02,\n",
       "       -4.24973331e-02, -1.08164260e-02,  2.66437009e-02, -5.68122044e-02,\n",
       "       -1.92345697e-02, -2.62186229e-02,  1.72658432e-02, -6.14875816e-02,\n",
       "        8.88397321e-02,  3.68176289e-02, -9.30379182e-02, -9.48854983e-02,\n",
       "       -2.46235747e-02, -9.46507044e-03,  1.17892995e-02,  3.14793698e-02,\n",
       "       -2.05881372e-02,  6.04239330e-02, -9.56953391e-02,  8.38091248e-04,\n",
       "       -8.71737227e-02, -1.11241480e-02,  4.79442440e-02,  1.65293310e-02,\n",
       "        1.01000912e-01, -6.24467842e-02, -1.01014664e-02, -4.37993463e-03,\n",
       "       -4.38602343e-02, -2.94696484e-02, -3.59923281e-02,  1.20374866e-01,\n",
       "        5.06209955e-02,  5.31427450e-02, -3.36068049e-02, -1.17527423e-02,\n",
       "        2.96493080e-02,  1.81944761e-02, -8.45836252e-02, -5.81792817e-02,\n",
       "       -1.34086117e-01,  1.48648685e-02,  3.26253213e-02, -7.05758622e-03,\n",
       "        3.35368402e-02, -6.02179356e-02, -3.38253789e-02,  7.38246646e-03,\n",
       "        4.01815437e-02, -9.14419964e-02, -8.79182015e-03, -2.58248076e-02,\n",
       "       -6.70124739e-02, -9.94836017e-02,  3.15810777e-02,  3.35202515e-02,\n",
       "       -6.44433275e-02, -4.59300913e-02, -1.70032412e-01,  4.31489497e-02,\n",
       "        6.26215413e-02, -5.99255960e-04,  2.05290020e-02,  2.81844456e-02,\n",
       "       -7.77938440e-02,  9.18384641e-04,  1.96230561e-02, -1.51909667e-08,\n",
       "        7.18876496e-02, -5.01595289e-02, -1.99028440e-02, -2.55277958e-02,\n",
       "       -7.61085004e-02, -2.54313145e-02, -5.94257377e-02,  4.84462874e-03,\n",
       "        2.05982346e-02,  1.41340584e-01,  6.81596901e-03,  9.03494377e-03,\n",
       "       -2.54336968e-02,  2.26991158e-03,  8.54653493e-03, -1.01634515e-02,\n",
       "       -1.01306597e-02, -4.17070873e-02, -6.07347488e-02, -4.58690114e-02,\n",
       "        5.01163211e-03,  1.33683942e-02,  6.43007830e-02,  1.57711506e-02,\n",
       "        2.27244874e-03, -3.07390261e-02,  1.03884691e-03,  7.67785832e-02,\n",
       "        2.96966005e-02, -4.63439859e-02,  6.14698268e-02,  4.69055586e-02,\n",
       "       -1.76516976e-02, -1.08397141e-01, -4.37401831e-02, -3.04761343e-03,\n",
       "        6.08421825e-02, -7.60630593e-02,  4.41553742e-02,  5.31189516e-02,\n",
       "       -1.76818203e-02,  7.05458373e-02,  5.91038316e-02, -4.65735272e-02,\n",
       "        4.97362390e-02,  3.78632592e-03, -5.74672297e-02,  2.00513471e-02,\n",
       "       -3.26271579e-02, -4.98692133e-02, -1.49165355e-02,  1.24596860e-02,\n",
       "        4.07785783e-03,  4.44901213e-02, -4.18160073e-02, -1.02752205e-02,\n",
       "        3.15251090e-02, -5.40564358e-02,  2.03911792e-02,  3.13866325e-02,\n",
       "        9.89309102e-02, -2.63141785e-02,  6.79433346e-02,  6.05502315e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"What is RAG?\"]\n",
    "query_embedding = model.encode(query)[0]\n",
    "query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a48004",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = np.dot(embeddings, query_embedding)\n",
    "top_idx = np.argmax(similarities)\n",
    "retrieved_doc = documents[top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d997a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAG combines retrievable and generation to provide accurate, grounded responses.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8f8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "prompt = f\"\"\"context: {retrieved_doc}\n",
    "\n",
    "Qusetion: {query}\n",
    "Answer based on the context:\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f811a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAG is a system that combines retrievable and generation techniques to provide accurate and grounded responses.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b2c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom RAG Answer\n",
      "RAG is a system that combines retrievable and generation techniques to provide accurate and grounded responses.\n"
     ]
    }
   ],
   "source": [
    "#Custom RAG\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "#1. Generate embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "#2. Query and retrieve\n",
    "query = \"What is RAG?\"\n",
    "query_embedding = model.encode([query])[0]\n",
    "\n",
    "#3. Compute Similarities\n",
    "similarities = np.dot(doc_embeddings, query_embedding)\n",
    "top_idx = np.argmax(similarities)\n",
    "retrieved_doc = documents[top_idx]\n",
    "\n",
    "#4. Generate response\n",
    "client = OpenAI(api_key=api_key)\n",
    "prompt = f\"\"\" Context: {retrieved_doc}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer based on the context\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"Custom RAG Answer\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a1613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-core langchain-community langchain-openai langchain-text-splitters --quiet\n",
    "!pip install faiss-cpu python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e4b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='RAG stands for \"retrieval-augmented generation.\" It combines retrieval and generation techniques to provide accurate and grounded responses.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 93, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-ClsAHtoelmvbuEIuugmhmlPmHjayx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b1187-a292-7d11-9c6b-0dbdd1c20a17-0' usage_metadata={'input_tokens': 93, 'output_tokens': 25, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "lc_docs = [Document(page_content=doc) for doc in documents]\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = api_key)\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    lc_docs,\n",
    "    embeddings,\n",
    "    collection_name=\"my_rag_collection\",\n",
    "    persist_directory= \"./chroma_db\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "#llm\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature = 0,\n",
    "    openai_api_key = api_key\n",
    ")\n",
    "\n",
    "#Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert assistant. Use ONLY the retrieved context.\"),\n",
    "    (\"human\", \"{question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "#Build RAG pipeline\n",
    "rag_chain = (\n",
    "    RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "#Query\n",
    "response = rag_chain.invoke(\"What is RAG\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eccaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "#Convert documents\n",
    "lc_docs = [Document(page_content=doc) for doc in documents]\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de44d339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.14.10-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.10 (from llama-index)\n",
      "  Downloading llama_index_core-0.14.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.6.10-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.13.2)\n",
      "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2025.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.28.1)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading llama_index_workflows-2.11.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (12.0.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.12.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.0.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.0.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.8.1)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.11.12)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading pypdf-6.4.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.22.0)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.1.6)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.16.0)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.26.1)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.0.3)\n",
      "Downloading llama_index-0.14.10-py3-none-any.whl (7.5 kB)\n",
      "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.14.10-py3-none-any.whl (11.9 MB)\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.9 MB 575.8 kB/s eta 0:00:20\n",
      "   - -------------------------------------- 0.5/11.9 MB 575.8 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.8/11.9 MB 517.2 kB/s eta 0:00:22\n",
      "   -- ------------------------------------- 0.8/11.9 MB 517.2 kB/s eta 0:00:22\n",
      "   --- ------------------------------------ 1.0/11.9 MB 561.0 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 1.0/11.9 MB 561.0 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 599.3 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 599.3 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 613.4 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 613.4 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 1.8/11.9 MB 592.1 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 2.1/11.9 MB 627.4 kB/s eta 0:00:16\n",
      "   ------- -------------------------------- 2.1/11.9 MB 627.4 kB/s eta 0:00:16\n",
      "   ------- -------------------------------- 2.4/11.9 MB 660.5 kB/s eta 0:00:15\n",
      "   -------- ------------------------------- 2.6/11.9 MB 688.0 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.9/11.9 MB 716.5 kB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 745.4 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 768.0 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.9 MB 794.7 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 3.9/11.9 MB 819.5 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 4.5/11.9 MB 873.7 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 4.7/11.9 MB 891.0 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 921.0 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 5.5/11.9 MB 962.1 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 5.8/11.9 MB 987.1 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 6.3/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.6/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.3/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.9/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.4/11.9 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.7/11.9 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.0/11.9 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/11.9 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.9/11.9 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "Downloading llama_index_llms_openai-0.6.10-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_readers_file-0.5.5-py3-none-any.whl (51 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_workflows-2.11.5-py3-none-any.whl (91 kB)\n",
      "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.5 MB 828.1 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.5 MB 866.5 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.8/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.1/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.4/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.6/11.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.7/11.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.9/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.2/11.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.5/11.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 5.5/11.5 MB 1.4 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.8/11.5 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.3/11.5 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.1/11.5 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.6/11.5 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.9/11.5 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.7/11.5 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.9/11.5 MB 1.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.4/11.5 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading pypdf-6.4.1-py3-none-any.whl (328 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, soupsieve, pypdf, griffe, defusedxml, aiosqlite, pandas, nltk, deprecated, beautifulsoup4, llama-index-instrumentation, llama-cloud, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 2.0.1\n",
      "    Uninstalling wrapt-2.0.1:\n",
      "      Successfully uninstalled wrapt-2.0.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.3\n",
      "    Uninstalling pandas-2.3.3:\n",
      "      Successfully uninstalled pandas-2.3.3\n",
      "Successfully installed aiosqlite-0.21.0 banks-2.2.0 beautifulsoup4-4.14.3 defusedxml-0.7.1 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.15.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.10 llama-index-cli-0.5.3 llama-index-core-0.14.10 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.10 llama-index-readers-file-0.5.5 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.11.5 llama-parse-0.6.54 nltk-3.9.2 pandas-2.2.3 pypdf-6.4.1 soupsieve-2.8 striprtf-0.0.26 wrapt-1.17.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3149fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama index Answer\n",
      "RAG is a system that combines retrievable and generation techniques to provide accurate and grounded responses.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI as LlamaOpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "#Configure llamaindex\n",
    "Settings.llm = LlamaOpenAI(model=\"gpt-3.5-turbo\", temperature = 0, api_key = api_key)\n",
    "Settings.embed_model = OpenAIEmbedding(api_key= api_key)\n",
    "\n",
    "#Create documents and index\n",
    "llama_docs = [Document(text=doc) for doc in documents]\n",
    "index = VectorStoreIndex.from_documents(llama_docs)\n",
    "\n",
    "#Query\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is RAG?\")\n",
    "\n",
    "print(\"Llama index Answer\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e77a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
