{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63305b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839530c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baecee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model produces 384 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(f\"Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea44681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text The cat sat on the mat\n",
      "Embedding shape: (384,)\n",
      "First ten values: [ 0.13040183 -0.01187012 -0.02811707  0.05123867 -0.05597445  0.03019156\n",
      "  0.03016133  0.02469836 -0.01837058  0.0587668 ]\n"
     ]
    }
   ],
   "source": [
    "text = \"The cat sat on the mat\"\n",
    "embedding = model.encode(text)\n",
    "print(f\"Original text {text}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"First ten values: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Similarity function ready!\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    vec1_scalar = np.linalg.norm(vec1)\n",
    "    vec2_scalar = np.linalg.norm(vec2)\n",
    "    return dot_product / (vec1_scalar * vec2_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff79546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A feline rested on the rug\",      # Similar meaning, different words\n",
    "    \"Dogs are loyal animals\",          # Different topic\n",
    "    \"Python is a programming language\" # Completely unrelated\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebbb6763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to The cat sat on the mat\n",
      "Score: 1.0000001192092896\n",
      "\n",
      "Similarity to A feline rested on the rug\n",
      "Score: 0.5643377304077148\n",
      "\n",
      "Similarity to Dogs are loyal animals\n",
      "Score: 0.16523928940296173\n",
      "\n",
      "Similarity to Python is a programming language\n",
      "Score: 0.0308724083006382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"Similarity to {sentence}\")\n",
    "    print(f\"Score: {similarity}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da319fbe",
   "metadata": {},
   "source": [
    "### Simple Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d7dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base: 8 documents\n"
     ]
    }
   ],
   "source": [
    "# Sample knowledge base\n",
    "documents = [\n",
    "    \"Python is a high-level programming language known for simplicity\",\n",
    "    \"Machine learning enables computers to learn from data\",\n",
    "    \"Neural networks are inspired by biological brains\",\n",
    "    \"Dogs are loyal and friendly pets that need exercise\",\n",
    "    \"Cats are independent animals that make great companions\",\n",
    "    \"JavaScript is used for web development and runs in browsers\",\n",
    "    \"Deep learning uses multi-layered neural networks\",\n",
    "    \"Puppies require training and socialization from an early age\"\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base: {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42131e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 embeddings\n",
      "Each embedding has 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "#Create embeddings\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"Created {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {embeddings[0].shape[0]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f081079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, documents, doc_embeddings, top_k):\n",
    "    query_embedding = model.encode(query)\n",
    "    similarities = []\n",
    "    for index, embedding in enumerate(doc_embeddings):\n",
    "        similarity = cosine_similarity(embedding, query_embedding)\n",
    "        similarities.append((documents[index], similarity))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "714e1a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY: What is artificial intelligence?\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.408)\n",
      "   Machine learning enables computers to learn from data\n",
      "\n",
      "2. (Score: 0.395)\n",
      "   Neural networks are inspired by biological brains\n",
      "\n",
      "3. (Score: 0.326)\n",
      "   Python is a high-level programming language known for simplicity\n",
      "\n",
      "================================================================================\n",
      "QUERY: Tell me about pet dogs\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.548)\n",
      "   Dogs are loyal and friendly pets that need exercise\n",
      "\n",
      "2. (Score: 0.437)\n",
      "   Puppies require training and socialization from an early age\n",
      "\n",
      "3. (Score: 0.413)\n",
      "   Cats are independent animals that make great companions\n",
      "\n",
      "================================================================================\n",
      "QUERY: How do I code in Python?\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.554)\n",
      "   Python is a high-level programming language known for simplicity\n",
      "\n",
      "2. (Score: 0.148)\n",
      "   Puppies require training and socialization from an early age\n",
      "\n",
      "3. (Score: 0.138)\n",
      "   JavaScript is used for web development and runs in browsers\n"
     ]
    }
   ],
   "source": [
    "# Test different queries\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me about pet dogs\",\n",
    "    \"How do I code in Python?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    results = search(query, documents, embeddings, top_k=3)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. (Score: {score:.3f})\")\n",
    "        print(f\"   {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "270eafd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Deep learning uses multi-layered neural networks', np.float32(0.31909025))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eafe7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Both models loaded!\n",
      "Small model: 384 dimensions\n",
      "Large model: 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Load two different models for comparison\n",
    "print(\"Loading models...\\n\")\n",
    "\n",
    "model_small = SentenceTransformer('all-MiniLM-L6-v2')      # 384 dimensions\n",
    "model_large = SentenceTransformer('all-mpnet-base-v2')     # 768 dimensions\n",
    "\n",
    "print(\"✅ Both models loaded!\")\n",
    "print(f\"Small model: {model_small.get_sentence_embedding_dimension()} dimensions\")\n",
    "print(f\"Large model: {model_large.get_sentence_embedding_dimension()} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ed97c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing model performance:\n",
      "\n",
      "Pair: 'The dog is running' vs 'A canine is jogging'\n",
      "  Small model: 0.818\n",
      "  Large model: 0.827\n",
      "\n",
      "Pair: 'I love pizza' vs 'Pizza is delicious'\n",
      "  Small model: 0.801\n",
      "  Large model: 0.785\n",
      "\n",
      "Pair: 'Python programming' vs 'Cooking pasta'\n",
      "  Small model: 0.142\n",
      "  Large model: 0.120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare on a similarity task\n",
    "test_pairs = [\n",
    "    (\"The dog is running\", \"A canine is jogging\"),           # Similar\n",
    "    (\"I love pizza\", \"Pizza is delicious\"),                  # Related\n",
    "    (\"Python programming\", \"Cooking pasta\")                  # Unrelated\n",
    "]\n",
    "\n",
    "print(\"Comparing model performance:\\n\")\n",
    "for text1, text2 in test_pairs:\n",
    "    # Small model\n",
    "    emb1_small = model_small.encode([text1, text2])\n",
    "    sim_small = cosine_similarity(emb1_small[0], emb1_small[1])\n",
    "    \n",
    "    # Large model  \n",
    "    emb1_large = model_large.encode([text1, text2])\n",
    "    sim_large = cosine_similarity(emb1_large[0], emb1_large[1])\n",
    "    \n",
    "    print(f\"Pair: '{text1}' vs '{text2}'\")\n",
    "    print(f\"  Small model: {sim_small:.3f}\")\n",
    "    print(f\"  Large model: {sim_large:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec073d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
